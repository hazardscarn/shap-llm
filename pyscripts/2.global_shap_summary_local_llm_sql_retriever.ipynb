{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\Github\\shap-llm\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Work\\Github\\shap-llm\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Work\\Github\\shap-llm\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser,StrOutputParser\n",
    "\n",
    "from langchain import hub\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import END, StateGraph\n",
    "from pprint import pprint\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name='all-MiniLM-L12-v2'\n",
    ")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from xgb_process import shap_summary,xgb_model\n",
    "from utils import generate_text_summary,create_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Telco Churn Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required columns are in the DataFrame.\n",
      "ROC AUC Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "###Load the table and add to database\n",
    "df0=pd.read_csv(\"..\\\\data\\\\telco_churn_data.csv\",index_col=False)\n",
    "df0.columns = [x.lower() for x in df0.columns]\n",
    "cat_cols = ['gender', 'seniorcitizen', 'partner', 'dependents', 'phoneservice', 'multiplelines', 'internetservice',\n",
    "            'onlinesecurity', 'onlinebackup', 'deviceprotection', 'techsupport', 'streamingtv', 'streamingmovies',\n",
    "            'contract', 'paperlessbilling', 'paymentmethod']\n",
    "num_cols = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "target = 'churn'\n",
    "\n",
    "# Ensure the target variable and all feature names in the lists are exactly as in the DataFrame\n",
    "if set(cat_cols + num_cols + [target]).issubset(df0.columns):\n",
    "    print(\"All required columns are in the DataFrame.\")\n",
    "else:\n",
    "    missing_cols = set(cat_cols + num_cols + [target]) - set(df0.columns)\n",
    "    print(\"Missing columns:\", missing_cols)\n",
    "\n",
    "##Ensure target is numeric\n",
    "df0[target] = df0[target].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "# Convert categorical columns to 'category' dtype\n",
    "df0[cat_cols] = df0[cat_cols].astype('category')\n",
    "\n",
    "# Convert numeric columns to 'numeric' dtype\n",
    "for col in num_cols:\n",
    "    df0[col] = pd.to_numeric(df0[col], errors='coerce')\n",
    "df0['customerid']=df0['customerid'].astype('category')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize and use the model\n",
    "model_instance = xgb_model.XGBoostModel(df=df0, cat_features=cat_cols, num_features=num_cols, target=target, mode='dev')\n",
    "model,dtrain,X_train,dtest,X_test=model_instance.train_model()\n",
    "\n",
    "\n",
    "analyzer=shap_summary.ShapAnalyzer(model=model,\n",
    "                                X_train=X_train,\n",
    "                                dtrain=dtrain,\n",
    "                                cat_features=cat_cols,\n",
    "                                num_features=num_cols)\n",
    "\n",
    "result_df = analyzer.analyze_shap_values()\n",
    "summary_df = analyzer.summarize_shap_df()\n",
    "\n",
    "# Convert object types to category and numeric types to their respective numeric types\n",
    "for col in summary_df.columns:\n",
    "    if summary_df[col].dtype == 'object':\n",
    "        summary_df[col] = summary_df[col].astype('category')\n",
    "    elif pd.api.types.is_numeric_dtype(summary_df[col]):\n",
    "        summary_df[col] = pd.to_numeric(summary_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class to Add table to Database and to Query DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddTabletoDatabase:\n",
    "    def __init__(self, db_name, db_path='.'):\n",
    "        self.db_path = os.path.join(db_path, db_name)\n",
    "        self.conn = sqlite3.connect(self.db_path)\n",
    "        print(f\"Database {db_name} connected at {db_path}\")\n",
    "\n",
    "    def add_table(self, df, table_name):\n",
    "        dtype_dict = {col: 'TEXT' if ((df[col].dtype=='category')|(df[col].dtype=='object')) else 'REAL' for col in df.columns}\n",
    "        df.to_sql(table_name, self.conn, if_exists='replace', index=False, dtype=dtype_dict)\n",
    "        print(f\"Table {table_name} Added.\")\n",
    "\n",
    "    def delete_table(self, table_name):\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';\")\n",
    "        if cur.fetchone():\n",
    "            cur.execute(f\"DROP TABLE {table_name};\")\n",
    "            print(f\"Table {table_name} deleted.\")\n",
    "        else:\n",
    "            return f\"No such table: {table_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database my_database.db connected at ../sqldatabase\n",
      "Table shap_summary Added.\n"
     ]
    }
   ],
   "source": [
    "db = AddTabletoDatabase('my_database.db', '../sqldatabase')\n",
    "# db.add_table(df0, 'telco_data')\n",
    "db.add_table(summary_df, 'shap_summary')\n",
    "#db.delete_table('contract_info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up the Vector DataBase\n",
    "\n",
    "We will use Vector database for data dictionary and data summary Only. Any information about the model SHAP will be using SQL retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"..//documents//data_dictionary.txt\",\n",
    "    \"..//documents//data_summary.txt\",\n",
    "]\n",
    "\n",
    "docs = [TextLoader(url).load() for url in text]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=400, chunk_overlap=100\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"churn-rag-chroma-3\",\n",
    "    embedding=hf,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Util Functions Needed for the agent \n",
    "\n",
    "Some Util FUnctions are required to Get Schema, execute query, fomart documents etc.\n",
    "They will be defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    \"\"\"\n",
    "    Concatenates the page content of each document in the provided list.\n",
    "\n",
    "    This function takes a list of document objects and concatenates the \n",
    "    'page_content' attribute of each document, separating them with two newline \n",
    "    characters.\n",
    "\n",
    "    Args:\n",
    "        docs (list): A list of document objects. Each object is expected to have \n",
    "                     a 'page_content' attribute.\n",
    "\n",
    "    Returns:\n",
    "        str: A string containing the concatenated page content of all documents.\n",
    "    \"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "def get_all_schemas(db_name=\"my_database.db\", db_path=\"../sqldatabase\"):\n",
    "    \"\"\"\n",
    "    Retrieves all tables and their schemas from a SQLite database.\n",
    "\n",
    "    Args:\n",
    "        db_name (str): The name of the SQLite database file.\n",
    "        db_path (str): The directory path where the SQLite database file is located.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representation of all tables and their schemas in the database.\n",
    "    \"\"\"\n",
    "    db_path = os.path.join(db_path, db_name)\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Get all tables\n",
    "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = [table[0] for table in cur.fetchall()]\n",
    "    \n",
    "    output = \"Tables:\\n\"\n",
    "    output += \"\\n\".join(tables)\n",
    "    output += \"\\n\\nSchemas:\\n\"\n",
    "    \n",
    "    for table in tables:\n",
    "        # Get table schema\n",
    "        cur.execute(f\"PRAGMA table_info({table});\")\n",
    "        schema = [(column[1], column[2], 'NULLABLE' if column[3] == 0 else 'NOT NULL') for column in cur.fetchall()]\n",
    "        \n",
    "        output += f\"{table}:\\n\"\n",
    "        for column in schema:\n",
    "            output += f\"  Name: {column[0]}, Type: {column[1]}, Mode: {column[2]}\\n\"\n",
    "        \n",
    "        output += \"\\nDistinct Values for Categorical Variables:\\n\"\n",
    "        for column_name, column_type, _ in schema:\n",
    "            if column_type == 'TEXT':\n",
    "                cur.execute(f'SELECT DISTINCT \"{column_name}\" FROM \"{table}\";')\n",
    "                values = [row[0] for row in cur.fetchall()]\n",
    "                if ((len(values) < 20) &(len(values)>0) ):\n",
    "                    output += f\"  {column_name}: {values}\\n\"\n",
    "            elif column_type == 'REAL':\n",
    "                cur.execute(f'SELECT AVG(\"{column_name}\") FROM \"{table}\";')\n",
    "                mean_value = cur.fetchone()[0]\n",
    "                output += f\"  Mean value of `{column_name}`: {mean_value}\\n\"  # Enclose column name in backticks\n",
    "    \n",
    "    conn.close()\n",
    "    return output\n",
    "\n",
    "\n",
    "# def get_schema(_):\n",
    "#     \"\"\"\n",
    "#     Wrapper function for get_all_schemas with no arguments.\n",
    "\n",
    "#     Returns:\n",
    "#         str: A string representation of all tables and their schemas in the database.\n",
    "#     \"\"\"\n",
    "#     return get_all_schemas()\n",
    "\n",
    "# def get_messages(_):\n",
    "#     \"\"\"\n",
    "#     Retrieves and concatenates all messages from the global 'hist' object.\n",
    "\n",
    "#     Returns:\n",
    "#         str: A string containing all messages, separated by three newline characters.\n",
    "#     \"\"\"\n",
    "#     messages = [message.content for message in hist.messages]\n",
    "#     concatenated_messages = '\\n\\n\\n '.join(messages)\n",
    "#     return concatenated_messages\n",
    "\n",
    "# def execute_query_with_retries(my_query,database='my_database.db', max_attempts=5):\n",
    "#     \"\"\"\n",
    "#     Attempts to execute a SQL query on a SQLite database with a specified number of retries.\n",
    "\n",
    "#     Args:\n",
    "#         my_query (str): The SQL query to execute.\n",
    "#         database (str): The name of the SQLite database file.\n",
    "#         max_attempts (int): The maximum number of attempts to execute the query.\n",
    "\n",
    "#     Returns:\n",
    "#         DataFrame, str: A pandas DataFrame containing the query results and the cleaned SQL query.\n",
    "#         If the query fails, returns None and the cleaned SQL query.\n",
    "#     \"\"\"\n",
    "\n",
    "#     conn = sqlite3.connect(database)\n",
    "#     cur = conn.cursor()\n",
    "#     attempts = 0\n",
    "#     while attempts < max_attempts:\n",
    "#         attempts += 1\n",
    "#         print(f\"Attempt {attempts} of {max_attempts}\")\n",
    "#         # Invoke the external SQL service\n",
    "#         print(\"Generating the SQL\")\n",
    "#         # cur.execute(my_query)\n",
    "#         #result = cur.fetchall()\n",
    "#         # answer_generation=sql_generator_rag_chain.invoke({\"question\": my_query,\"schema\": agent.get_all_schemas(),\"messages\":hist.messages})\n",
    "#         answer_generation=sql_response.invoke({\"question\": my_query})\n",
    "#         clean_sql = extract_sql(answer_generation)\n",
    "#         print(f\"SQL Query: {clean_sql}\")\n",
    "#         if clean_sql=='None':\n",
    "#             print(\"No query logic found for this question from database\")\n",
    "#         else:\n",
    "#             try:\n",
    "#                 print(\"Attempting to run the query and convert it to a DataFrame\")\n",
    "#                 dataframe = agent.execute_query(clean_sql)\n",
    "#                 if dataframe.shape[0]==0:\n",
    "#                     print(\"Empty DataFrame returned\")\n",
    "#                     hist.add_user_message(clean_sql + ': ' + \"Empty DataFrame returned. If using any ID filter make sure it matches the users input\")\n",
    "#                     if attempts == max_attempts:\n",
    "#                         print(\"Reached maximum attempt limit. Stopping retries.\")\n",
    "#                         return [],clean_sql  # Return None if all retries fail\n",
    "#                 else:\n",
    "#                     print(\"Query executed successfully.\")\n",
    "#                     return dataframe,clean_sql\n",
    "#             except Exception as e:\n",
    "#                 # Print or store the error message\n",
    "#                 error_message = str(e)\n",
    "#                 print(\"Query failed with the following error:\")\n",
    "#                 print(error_message)\n",
    "#                 hist.add_user_message(clean_sql + ': ' + error_message)\n",
    "#                 if attempts == max_attempts:\n",
    "#                     print(\"Reached maximum attempt limit. Stopping retries.\")\n",
    "#                     return None  # Return None if all retries fail\n",
    "#                     return [],clean_sql\n",
    "#     conn.close()\n",
    "\n",
    "def execute_query(query,database=\"my_database.db\",db_path=\"../sqldatabase\"):\n",
    "        \n",
    "        db_path = os.path.join(db_path, database)\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(query)\n",
    "        rows = cur.fetchall()\n",
    "        column_names = [column[0] for column in cur.description]\n",
    "        return pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "def extract_sql(input_text):\n",
    "    \"\"\"\n",
    "    Extracts SQL code from a string.\n",
    "\n",
    "    The function looks for SQL code enclosed in triple backticks. If no triple backticks are found,\n",
    "    it returns the input string as is.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The input string.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted SQL code, or the input string if no SQL code is found.\n",
    "    \"\"\"\n",
    "    # Check if the input contains triple backticks\n",
    "    if '```' in input_text:\n",
    "        # Regex to extract content within triple backticks\n",
    "        pattern = re.compile(r'```(.*?)```', re.DOTALL)\n",
    "        match = pattern.search(input_text)\n",
    "        if match:\n",
    "            return match.group(1).strip()  # Return the cleaned, extracted SQL\n",
    "    # If no triple backticks are found, return the input as is\n",
    "    return input_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Components for The SQL Retriver LangGraph Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Agent 1- Retrieval Grader\n",
    "retrieval_prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keywords related to the user question, grade it as relevant. \\n\n",
    "        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "        Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\"\"\",\n",
    "        input_variables=[\"question\", \"document\"],\n",
    "    )\n",
    "\n",
    "llm = ChatOllama(model=\"llama3:latest\", format=\"json\", temperature=0)\n",
    "retrieval_grader = retrieval_prompt | llm | JsonOutputParser()\n",
    "retriever=vectorstore.as_retriever(search_type='similarity',search_kwargs={'k': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Agent 2 -  Business Analyst Agent\n",
    "buisiness_analyst_prompt = PromptTemplate(\n",
    "    template=\"\"\" You are a business analyst for a telecom company. \n",
    "            Your job is to create a report for senior executives on questions asked. \n",
    "            Answer ONLY with stats you got from the context provided.\n",
    "            DO NOT add any erronous stats.\n",
    "\n",
    "            Context: {context}\n",
    "\n",
    "            Question: {question}\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "generator_llm = ChatOllama(model=\"llama3:latest\",temperature=0)\n",
    "# Chain\n",
    "business_analyst_rag_chain = buisiness_analyst_prompt | generator_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Agent 3 - Hallucination Grader \n",
    "\n",
    "llm = ChatOllama(model=\"llama3:latest\", format=\"json\", temperature=0)\n",
    "# Prompt\n",
    "hallucination_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an answer is grounded in / supported by a set of facts. \\n \n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the answer is grounded in / supported by a set of facts. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Agent 4 - Answer Grader \n",
    "# Prompt\n",
    "answer_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an answer is useful to resolve a question. \\n \n",
    "    Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question}\n",
    "    Give a binary score 'yes' or 'no' to indicate whether the answer is useful to resolve a question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = answer_grader_prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Agent 5 - Question Re-writer\n",
    "re_write_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vectorstore retrieval. Look at the initial and formulate an improved question. \\n\n",
    "     Here is the initial question: \\n\\n {question}.\n",
    "     ONLY RETURN THE REWRITTEN QUESTION.\\n\n",
    "     DONOT ADD ANY TEXT OTHER THAN REWRITTEN QUESTION.\\n\n",
    "     Improved question with no preamble: \\n \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "rewrite_llm = ChatOllama(model=\"llama3:latest\", temperature=0)\n",
    "question_rewriter = re_write_prompt | rewrite_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Agent 6 - SQL Question Reframer\n",
    "\n",
    "sql_qprompt = PromptTemplate(\n",
    "    template=\"\"\"Given the user's question and the database schema, your task is to reframe the question to better suit the data available.\n",
    "\n",
    "    Remember:\n",
    "        - 'feature_group' refers to different groups within a feature.\n",
    "        - 'feature_effect' indicates if a feature increases or decreases the contribution towards the target.\n",
    "        - 'probability_contribution' measures the feature group's contribution towards the target.\n",
    "        - 'Feature_Importance_Rank' shows the importance of the feature in model predictions; a lower rank means higher importance.\n",
    "        - The target outcome to analyze is 'churn'.\n",
    "\n",
    "            Schema: {schema}\n",
    "\n",
    "            Sample User Question: \"What are the top N reasons that *prevent* Churn?\"\n",
    "            Expected Reframed Question: \"Select top N feature groups along with feature based on the highest probability contribution and feature effect as decreases.\"\n",
    "\n",
    "            Sample Question: \"What are the top N reasons *for* Churn?\"\n",
    "            Expected Reframed Question: \"Select top N feature groups along with feature based on the highest probability contribution and feature effect as increases.\"\n",
    "\n",
    "            Sample User Question: \"What are the top N features?\"\n",
    "            Expected Reframed Question: \"Select top N distict features in the increasing order of feature importance rank.\"\n",
    "\n",
    "            Always add feature_effect,probability_contribution and Feature_Importance_Rank in the final table if it was used.\n",
    "\n",
    "            Please return ONLY the reframed question.\n",
    "\n",
    "            User Question : {question}\n",
    "    \"\"\",input_variables=[\"question\", \"schema\"],\n",
    ")\n",
    "\n",
    "\n",
    "sql_q_llm = ChatOllama(model=\"llama3:latest\",temperature=0)\n",
    "sql_question_chain = sql_qprompt | sql_q_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent 7 - SQL Query Generator\n",
    "sql_query_prompt = PromptTemplate(\n",
    "        template=\"\"\"Based on the Sqlite database schema below, and the message history, write a\n",
    "        SQL query that answers the question/request.\n",
    "        DONOT add sql before the query generated. Return the query only.\n",
    "        Only return a query if a possible query logic exists.\n",
    "        Reply None if there is no possible query for given question from schema\n",
    "\n",
    "\n",
    "        Question: {sql_question}\n",
    "\n",
    "        Remember to UNNEST repeated records and make sure only to use exisiting fields in the schema:\n",
    "\n",
    "        schema:{schema}\n",
    "\n",
    "        **If question asks for Top N remember to return top N records as specified in the order as instructed**\n",
    "        **Never sort Feature_Importance_Rank in DESC order**\n",
    "\n",
    "\n",
    "        Query should include all the columns needed to answer the question.\n",
    "        All columns used in filter and groups should be added in final table\n",
    "\n",
    "        SQL Query:\"\"\",input_variables=[\"sql_question\", \"schema\"],\n",
    "    \n",
    ")\n",
    "\n",
    "sql_generator_llm = ChatOllama(model=\"llama3:latest\",temperature=0)\n",
    "#sql_query_chain = RunnablePassthrough.assign(schema=get_schema, messages=get_messages)|sql_query_prompt|sql_generator_llm|StrOutputParser()\n",
    "sql_query_chain = sql_query_prompt | sql_generator_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent 8 - SQL Query Validator\n",
    "\n",
    "query_evaluator_prompt=PromptTemplate(\n",
    "    template=\"\"\"Your task is to assess a sql query and see if it is appropriate to answer the question. You will be provided the question, query and the schema of the database query will be ran on.\n",
    "\n",
    "\n",
    "        schema:{schema}\n",
    "\n",
    "        question : {question}\n",
    "\n",
    "        query : {query}\n",
    "\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the answer is grounded in / supported by a set of facts. \\n\n",
    "        Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\",\n",
    "                                        input_variables=[\"schema\", \"question\",\"query\"],\n",
    "                                            \n",
    "                                        )\n",
    "\n",
    "query_evaluator_llm = ChatOllama(model=\"llama3:latest\", format=\"json\", temperature=0)\n",
    "query_evaluator_chain = query_evaluator_prompt|query_evaluator_llm|JsonOutputParser()\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent 9 - Feature Description\n",
    "\n",
    "feature_description_prompt = PromptTemplate(\n",
    "    template=\"\"\" You are an expert document researcher. Your job is to analyze multiple sources to provide detailed descriptions for the question passed.\n",
    "      Each description should be concise, informative, and directly related to the values in question. Use the following guidelines for your research:\n",
    "\n",
    "    1. **Accuracy**: Ensure that the information you provide is accurate and sourced from credible documents.\n",
    "    2. **Relation**: For each feature provide information about different groups present\n",
    "    3. Donot add any extra information unrelated to the request\n",
    "    4. Donot provide any extra summary\n",
    "    5. Add note if the feature belongs to a static, action or dynamic context. Just mention which one it belongs to\n",
    "\n",
    "    Here is the question:\n",
    "\n",
    "            question: {question}\n",
    "\n",
    "    Here is the context:\n",
    "\n",
    "            context: {context}\n",
    "\"\"\",\n",
    "    input_variables=[\"question\",\"context\"],\n",
    ")\n",
    "\n",
    "generator_llm = ChatOllama(model=\"llama3:latest\",temperature=0)\n",
    "# Chain\n",
    "feature_description_rag_chain = feature_description_prompt | generator_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent 10 - Manager Agent\n",
    "manager_prompt = PromptTemplate(\n",
    "    template=\"\"\" You are manager of data science team for a telecom company. \n",
    "                You get different reports on churn from your business analyst in your team.\n",
    "                Your job is to format and proof read the report provided to you by the business analyst and create a enriched report for senior executive team.\n",
    "                The end user might not be tech savvy, so keep the language easy to understand\n",
    "                Answer should be properly formatted and user friendly and easy to understand.\n",
    "\n",
    "                feature : The general feature\n",
    "                feature_group : The subgroup of feature that provides churn contribution\n",
    "                feature_effect : specifies if it increases or decreases churn\n",
    "                probability_contribution : How much the feature group increases or decreases churn based on the baseline\n",
    "\n",
    "            \n",
    "            Question: {question}\n",
    "\n",
    "            Use the below report from business analyst to create final report. Look athe feature groups carefully and explain based on each and every feature groups:\n",
    "\n",
    "            Report: {context}\n",
    "\n",
    "            DONOT add any extra information not available to you. Answer from the infomration provided ONLY.\n",
    "            Interpret decimal points properly. DONOT read 85.12 as 8512.\n",
    "\n",
    "            \"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "llm=ChatOllama(model=\"llama3:latest\",temperature=0)\n",
    "manager_rag_chain = manager_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the SQL Agent Graph Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqlGraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        sql_question: reframed question for SQL query generation\n",
    "        sql_query: Sql Query Gernerated by Agent\n",
    "        schema: Schema of SQL database\n",
    "        hist: History of SQL Queries created \n",
    "        sql_output : Output from SQL Query execution\n",
    "        feature_lookup : description for each important features\n",
    "        output : final output from SQL Agent\n",
    "        report : final report from Manager Agent\n",
    "    \"\"\"\n",
    "    question : str\n",
    "    sql_question : str\n",
    "    sql_query : str\n",
    "    schema : str\n",
    "    hist: str\n",
    "    sql_output : pd.DataFrame\n",
    "    feature_lookup: str\n",
    "    output:str\n",
    "    report: str\n",
    "\n",
    "\n",
    "### Nodes\n",
    "\n",
    "def question_reframe(state):\n",
    "\n",
    "    print(\"---Reframe Question for SQL Agent---\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    sql_question = sql_question_chain.invoke({\"schema\": get_all_schemas(), \"question\": question})\n",
    "    return {\"question\": question, \"sql_question\": sql_question}\n",
    "\n",
    "def query_creation(state):\n",
    "\n",
    "    print(\"---Creating the SQL Query---\")\n",
    "    sql_question = state[\"sql_question\"]\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    sql_query = sql_query_chain.invoke({\"schema\": get_all_schemas(), \"sql_question\": sql_question})\n",
    "    return {\"question\": question, \"sql_query\": sql_query}\n",
    "\n",
    "\n",
    "def execute_sql_query(state):\n",
    "\n",
    "    print(\"--------------Running SQL Query-----------\")\n",
    "    if 'sql_query' not in state:\n",
    "        print(\"No SQL query provided in the state.\")\n",
    "        return {\"sql_output\": [], \"sql_query\": None}\n",
    "\n",
    "    sql_query_created = state['sql_query']\n",
    "    clean_sql = extract_sql(sql_query_created)\n",
    "    conn = sqlite3.connect('my_database.db')\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    #print(f\"SQL Query: {clean_sql}\")\n",
    "    if clean_sql == 'None':\n",
    "        print(\"No query logic found for this question from database\")\n",
    "    else:\n",
    "        try:\n",
    "            print(\"Attempting to run the query and convert it to a DataFrame\")\n",
    "            dataframe = execute_query(query=clean_sql)\n",
    "            dataframe = dataframe.reset_index(drop=True)\n",
    "            if dataframe.shape[0] == 0:\n",
    "                print(\"Empty DataFrame returned\")\n",
    "                return {\"sql_output\": [], \"sql_query\": clean_sql}\n",
    "            else:\n",
    "                print(\"Query executed successfully.\")\n",
    "                return {\"sql_output\": dataframe, \"sql_query\": clean_sql}\n",
    "        except Exception as e:\n",
    "            # Print or store the error message\n",
    "            error_message = str(e)\n",
    "            print(\"Query failed with the following error:\")\n",
    "            print(error_message)\n",
    "            return {\"sql_output\": [], \"sql_query\": clean_sql}\n",
    "    conn.close()\n",
    "\n",
    "def add_feature_description(state):\n",
    "\n",
    "    print(\"--------------Adding Feature Description-----------\")\n",
    "    sql_output=state[\"sql_output\"]\n",
    "\n",
    "    try:\n",
    "        if isinstance(sql_output, pd.DataFrame) and 'feature' in sql_output.columns and not sql_output['feature'].empty:\n",
    "            f_query=f_query = \"Provide description for \" + ', '.join(sql_output['feature'].unique())+\"?\"\n",
    "            f_retriever=vectorstore.as_retriever(search_type='similarity',search_kwargs={'k': 3})\n",
    "            documents = f_retriever.invoke(f_query)\n",
    "            retrived_doc=format_docs(docs=documents)\n",
    "            feature_description=feature_description_rag_chain.invoke({\"question\":f_query,\"context\":retrived_doc})\n",
    "            #print(feature_description)\n",
    "            return {\"feature_lookup\": feature_description}\n",
    "        else:\n",
    "            print(\"Either the DataFrame 'sql_output' does not exist, the column 'feature' does not exist in it, or it does not have at least one value.\")\n",
    "            return {\"feature_lookup\": \"\"}\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return {\"feature_lookup\": \"\"}\n",
    "\n",
    "def sql_report(state):\n",
    "    print(\"--------------Combine SQL Output and Feature Description------------\")\n",
    "    # Convert the DataFrame to a string\n",
    "    dataframe_string = state['sql_output'].to_string()\n",
    "\n",
    "    # Convert the feature lookup list to a string\n",
    "    feature_lookup_string = state['feature_lookup']\n",
    "\n",
    "    # Combine the DataFrame string and the feature lookup string\n",
    "    message = dataframe_string + \"\\n\" + feature_lookup_string\n",
    "\n",
    "    return {\"output\": message}\n",
    "\n",
    "\n",
    "def manager_report(state):\n",
    "    print(\"--------------Creating Final Report------------\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    sql_report_output=state[\"output\"]\n",
    "    final_report=manager_rag_chain.invoke({\"question\":question,\"context\":sql_report_output})\n",
    "    return {\"report\": final_report}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple Agent Design. We haven't added the adaptive RAG framework here. This is to explain the SQL retriver component only. We can design hierarchical agent system of RAG and SQL retriver separately built over this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_workflow = StateGraph(SqlGraphState)\n",
    "\n",
    "# Define the nodes\n",
    "sql_workflow.add_node(\"question_reframe\", question_reframe)\n",
    "sql_workflow.add_node(\"query_creation\", query_creation)\n",
    "sql_workflow.add_node(\"execute_sql_query\", execute_sql_query)\n",
    "sql_workflow.add_node(\"add_feature_description\", add_feature_description)\n",
    "sql_workflow.add_node(\"sql_report\", sql_report)\n",
    "sql_workflow.add_node(\"manager_report\", manager_report)\n",
    "\n",
    "\n",
    "# Build graph\n",
    "sql_workflow.set_entry_point(\"question_reframe\")\n",
    "sql_workflow.add_edge(\"question_reframe\", \"query_creation\")\n",
    "sql_workflow.add_edge(\"query_creation\", \"execute_sql_query\")\n",
    "sql_workflow.add_edge(\"execute_sql_query\", \"add_feature_description\")\n",
    "sql_workflow.add_edge(\"add_feature_description\", 'sql_report')\n",
    "sql_workflow.add_edge(\"sql_report\", \"manager_report\")\n",
    "sql_workflow.add_edge(\"manager_report\", END)\n",
    "\n",
    "# Compile\n",
    "sql_chain_agent = sql_workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Reframe Question for SQL Agent---\n",
      "\"Node 'question_reframe':\"\n",
      "'\\n---\\n'\n",
      "---Creating the SQL Query---\n",
      "\"Node 'query_creation':\"\n",
      "'\\n---\\n'\n",
      "--------------Running SQL Query-----------\n",
      "Attempting to run the query and convert it to a DataFrame\n",
      "Query executed successfully.\n",
      "\"Node 'execute_sql_query':\"\n",
      "'\\n---\\n'\n",
      "--------------Adding Feature Description-----------\n",
      "\"Node 'add_feature_description':\"\n",
      "'\\n---\\n'\n",
      "--------------Combine SQL Output and Feature Description------------\n",
      "\"Node 'sql_report':\"\n",
      "'\\n---\\n'\n",
      "--------------Creating Final Report------------\n",
      "\"Node 'manager_report':\"\n",
      "'\\n---\\n'\n",
      "('**Top 20 Reasons for Churn and Recommended Actions**\\n'\n",
      " '\\n'\n",
      " 'Based on the report provided by our business analyst, we have identified the '\n",
      " 'top 20 features that contribute to churn. Here are the results:\\n'\n",
      " '\\n'\n",
      " '1. **Total Charges**: The total amount charged to the customer increases '\n",
      " 'churn by 16.70%. This suggests that customers who experience high charges '\n",
      " 'are more likely to leave the company.\\n'\n",
      " '\\n'\n",
      " 'Recommended Action: Review and optimize pricing strategies to ensure they '\n",
      " 'are fair and competitive.\\n'\n",
      " '\\n'\n",
      " '2. **Month-to-Month Contract**: Customers on month-to-month contracts are '\n",
      " '16.37% more likely to churn. This may indicate a lack of commitment or '\n",
      " 'satisfaction with the service.\\n'\n",
      " '\\n'\n",
      " 'Recommended Action: Offer incentives for customers to commit to longer-term '\n",
      " 'contracts, such as discounts or rewards.\\n'\n",
      " '\\n'\n",
      " '3. **Tenure**: The number of months a customer has stayed with the company '\n",
      " 'decreases churn by 13.87%. This suggests that long-term customers are more '\n",
      " 'likely to remain loyal.\\n'\n",
      " '\\n'\n",
      " 'Recommended Action: Focus on retaining existing customers through loyalty '\n",
      " 'programs and personalized services.\\n'\n",
      " '\\n'\n",
      " '4. **Monthly Charges**: High monthly charges increase churn by 12.70%. This '\n",
      " 'may indicate that customers feel they are not getting value for their '\n",
      " 'money.\\n'\n",
      " '\\n'\n",
      " 'Recommended Action: Review pricing strategies and consider offering tiered '\n",
      " 'pricing or discounts to make the service more affordable.\\n'\n",
      " '\\n'\n",
      " '5. **Tenure (2-6 months)**: Customers who have stayed with the company for '\n",
      " '2-6 months are 6.69% less likely to churn. This suggests that customers who '\n",
      " 'experience a smooth onboarding process are more likely to remain loyal.\\n'\n",
      " '\\n'\n",
      " 'Recommended Action: Streamline the onboarding process and provide excellent '\n",
      " 'customer service during this critical period.\\n'\n",
      " '\\n'\n",
      " '6. **Electronic Check Payment Method**: Customers who use electronic checks '\n",
      " 'as their payment method are 4.30% less likely to churn. This may indicate '\n",
      " 'that customers prefer the convenience of automatic payments.\\n'\n",
      " '\\n'\n",
      " 'Recommended Action: Offer incentives for customers to switch to electronic '\n",
      " 'check payments, such as rewards or discounts.\\n'\n",
      " '\\n'\n",
      " '7. **Fiber Optic Internet Service**: Customers with fiber optic internet '\n",
      " 'service are 3.94% less likely to churn. This suggests that high-speed '\n",
      " 'internet is a key factor in customer satisfaction.\\n'\n",
      " '\\n'\n",
      " 'Recommended Action: Continue to invest in improving and expanding fiber '\n",
      " 'optic internet services to meet customer demands.\\n'\n",
      " '\\n'\n",
      " '8. **No Online Security**: Customers without online security are 3.50% more '\n",
      " 'likely to churn. This may indicate that customers value the protection of '\n",
      " 'their online activities.\\n'\n",
      " '\\n'\n",
      " 'Recommended Action: Offer online security options as an add-on or bundle '\n",
      " 'with other services to increase customer satisfaction and retention.\\n'\n",
      " '\\n'\n",
      " '9. **Total Charges (85-275)**: The total amount charged to the customer '\n",
      " 'increases churn by 2.80%. This suggests that high charges are a key factor '\n",
      " 'in customer dissatisfaction.\\n'\n",
      " '\\n'\n",
      " 'Recommended Action: Review pricing strategies and consider offering tiered '\n",
      " 'pricing or discounts to make the service more affordable.\\n'\n",
      " '\\n'\n",
      " '10. **Tenure (6-12 months)**: Customers who have stayed with the company for '\n",
      " '6-12 months are 2.67% less likely to churn. This suggests that customers who '\n",
      " 'experience a smooth onboarding process are more likely to remain loyal.\\n'\n",
      " '\\n'\n",
      " 'Recommended Action: Streamline the onboarding process and provide excellent '\n",
      " 'customer service during this critical period.\\n'\n",
      " '\\n'\n",
      " 'The remaining features in the top 20 list include:\\n'\n",
      " '\\n'\n",
      " '11-19: These features contribute to churn, but their impact is smaller '\n",
      " 'compared to the top 10 features. They include factors such as payment '\n",
      " 'method, internet service provider, online backup, and tech support.\\n'\n",
      " '\\n'\n",
      " '**Recommended Actions**\\n'\n",
      " '\\n'\n",
      " 'Based on the analysis, we recommend the following actions to reduce churn:\\n'\n",
      " '\\n'\n",
      " '1. Review pricing strategies to ensure they are fair and competitive.\\n'\n",
      " '2. Offer incentives for customers to commit to longer-term contracts.\\n'\n",
      " '3. Focus on retaining existing customers through loyalty programs and '\n",
      " 'personalized services.\\n'\n",
      " '4. Streamline the onboarding process and provide excellent customer service '\n",
      " 'during this critical period.\\n'\n",
      " '5. Offer online security options as an add-on or bundle with other '\n",
      " 'services.\\n'\n",
      " '\\n'\n",
      " 'By implementing these actions, we can reduce churn and improve overall '\n",
      " 'customer satisfaction.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Run \n",
    "inputs = {\"question\": \"What are the top 20 reasons for churn? Provide atleast 5 recommeded actions to reduce churn.\"}\n",
    "for output in sql_chain_agent.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
