{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\Github\\shap-llm\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from xgb_process import shap_summary,xgb_model\n",
    "from utils import generate_text_summary,create_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\Github\\shap-llm\\venv\\Lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers\n",
    "import json\n",
    "from pprint import pprint  \n",
    "import xgboost as xgb\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import xgboost as xgb\n",
    "# import shap\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_PROJECT=\"DICE-LLM-Telco-Local-Explanations\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required columns are in the DataFrame.\n",
      "ROC AUC Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "###Load the table and add to database\n",
    "df0=pd.read_csv(\"..\\\\data\\\\telco_churn_data.csv\",index_col=False)\n",
    "df0.columns = [x.lower() for x in df0.columns]\n",
    "cat_cols = ['gender', 'seniorcitizen', 'partner', 'dependents', 'phoneservice', 'multiplelines', 'internetservice',\n",
    "            'onlinesecurity', 'onlinebackup', 'deviceprotection', 'techsupport', 'streamingtv', 'streamingmovies',\n",
    "            'contract', 'paperlessbilling', 'paymentmethod']\n",
    "num_cols = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "target = 'churn'\n",
    "\n",
    "# Ensure the target variable and all feature names in the lists are exactly as in the DataFrame\n",
    "if set(cat_cols + num_cols + [target]).issubset(df0.columns):\n",
    "    print(\"All required columns are in the DataFrame.\")\n",
    "else:\n",
    "    missing_cols = set(cat_cols + num_cols + [target]) - set(df0.columns)\n",
    "    print(\"Missing columns:\", missing_cols)\n",
    "\n",
    "##Ensure target is numeric\n",
    "df0[target] = df0[target].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "# Convert categorical columns to 'category' dtype\n",
    "df0[cat_cols] = df0[cat_cols].astype('category')\n",
    "\n",
    "# Convert numeric columns to 'numeric' dtype\n",
    "for col in num_cols:\n",
    "    df0[col] = pd.to_numeric(df0[col], errors='coerce')\n",
    "df0['customerid']=df0['customerid'].astype('category')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize and use the model\n",
    "model_instance = xgb_model.XGBoostModel(df=df0, cat_features=cat_cols, num_features=num_cols, target=target, mode='dev')\n",
    "model,dtrain,X_train,dtest,X_test=model_instance.train_model()\n",
    "\n",
    "\n",
    "analyzer=shap_summary.ShapAnalyzer(model=model,\n",
    "                                X_train=X_train,\n",
    "                                dtrain=dtrain,\n",
    "                                cat_features=cat_cols,\n",
    "                                num_features=num_cols)\n",
    "\n",
    "result_df = analyzer.analyze_shap_values()\n",
    "summary_df = analyzer.summarize_shap_df()\n",
    "\n",
    "# Convert object types to category and numeric types to their respective numeric types\n",
    "for col in summary_df.columns:\n",
    "    if summary_df[col].dtype == 'object':\n",
    "        summary_df[col] = summary_df[col].astype('category')\n",
    "    elif pd.api.types.is_numeric_dtype(summary_df[col]):\n",
    "        summary_df[col] = pd.to_numeric(summary_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create The Dice ConterFactual Model\n",
    "\n",
    "    - Dice doesn't support xgboost models directly. Currently it supports sklearn, pytorch and tensorflow\n",
    "    - However we don't need dice to explain why the churn, but need it to tell what if\n",
    "    - So we can use a base model within sklearn framework for this task\n",
    "    - Then use the base model to perform the what if analysis, and select the best actions recommended by base model and implement it with xgboost mdoel to understand the relative improvmenet from top recommendations from dice model to mnimize the churn score\n",
    "    - Below we will create the dice model and base model with sklearn framework\n",
    "    - We will use histogram gradient booster with sklearn for base model since it takes categorical variable without encoding and is fast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hist_model(X_train, y_train, cat_cols):\n",
    "    \"\"\"\n",
    "    Train a HistGradientBoostingClassifier model.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (DataFrame): The training data.\n",
    "    y_train (Series): The target values for the training data.\n",
    "    cat_cols (list): The categorical columns in the training data.\n",
    "\n",
    "    Returns:\n",
    "    HistGradientBoostingClassifier: The trained model.\n",
    "    \"\"\"\n",
    "    # Identify categorical feature indices\n",
    "    categorical_feature_indices = [X_train.columns.get_loc(col) for col in cat_cols]\n",
    "\n",
    "    # Train a HistGradientBoostingClassifier model\n",
    "    hist_model = HistGradientBoostingClassifier(categorical_features=categorical_feature_indices)\n",
    "    hist_model.fit(X_train, y_train)\n",
    "\n",
    "    return hist_model\n",
    "\n",
    "def create_dice_model(X_train, y_train, num_cols, cat_cols, hist_model):\n",
    "    \"\"\"\n",
    "    Create a DiCE model using a HistGradientBoostingClassifier model.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (DataFrame): The training data.\n",
    "    y_train (Series): The target values for the training data.\n",
    "    num_cols (list): The numerical columns in the training data.\n",
    "    cat_cols (list): The categorical columns in the training data.\n",
    "    hist_model (HistGradientBoostingClassifier): The trained HistGradientBoostingClassifier model.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the DiCE data object, the DiCE model object, and the DiCE explainer object.\n",
    "    \"\"\"\n",
    "    # Create a dataframe for DiCE\n",
    "    X_train_df = X_train.copy()\n",
    "    X_train_df['churn'] = y_train\n",
    "\n",
    "    # Create a DiCE data object\n",
    "    d = dice_ml.Data(dataframe=X_train_df, continuous_features=num_cols, outcome_name='churn', categorical_features=cat_cols)\n",
    "\n",
    "    # Create a DiCE model object using the HistGradientBoostingClassifier model\n",
    "    m = dice_ml.Model(model=hist_model, backend='sklearn')\n",
    "    exp = dice_ml.Dice(d, m)\n",
    "\n",
    "    return d, m,exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the dice model we will create 20 what if analysis with the action context features\n",
    "- Dice provides us control over : \n",
    "    1. what features to use in what if analysis, \n",
    "    2. set ranges for continous features\n",
    "    3. Maximize which Class 0 /1 (or the class to maximize in multiclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the summary of how DiCE generates counterfactual explanations using the random method, focusing on the query instance perspective:\n",
    "\n",
    "Imagine DiCE as a \"What If\" Tool for Your Machine Learning Model:\n",
    "\n",
    "- The Subject: You provide DiCE with a single example of data â€“ your query instance. This could be information about a customer, a patient, a loan applicant, or any other data your model makes predictions on.\n",
    "\n",
    "- Focus Areas: You tell DiCE which specific parts (features) of this data you want to explore changes in. For instance, with a customer, you might focus on their \"contract type\" or \"monthly charges\".\n",
    "\n",
    "- Tweaking the Details: DiCE then starts to create alternative versions of your query instance by making random changes to the selected features:\n",
    "\n",
    "    For numerical features (like income), DiCE adjusts the value up or down within a reasonable range.\n",
    "    For categorical features (like payment method), DiCE switches to a different category.\n",
    "\n",
    "- Exploring Possibilities:  Each change creates a new \"what if\" scenario â€“ a slightly different version of your original data. It's like asking, \"What if this customer had a different contract or paid a different amount?\"\n",
    "\n",
    "- Model's Perspective: DiCE shows each new scenario to your prediction model. This is to see how the changes might affect the model's outcome. Maybe a different contract type would lead the model to predict that a customer is less likely to leave (churn).\n",
    "\n",
    "- Finding the Most Interesting Changes:  DiCE collects the \"what if\" scenarios that cause the biggest changes in your model's predictions. These are the most informative because they highlight the features that strongly influence the model's decisions.\n",
    "\n",
    "- The \"total_CFs\" Parameter:\n",
    "\n",
    "    This tells DiCE how many unique \"what if\" scenarios you want to see. DiCE keeps generating new scenarios until it finds that many unique ones. This helps you get a diverse range of possible outcomes.\n",
    "\n",
    "- Other Important Parameters in explainer.generate_counterfactuals:\n",
    "\n",
    "    features_to_vary: The list of features you want to explore changes in.\n",
    "    desired_class: (Optional) If your model predicts categories, you can tell DiCE to focus on changes that lead to a specific category of prediction.\n",
    "    permitted_range: (Optional) You can control the range of values DiCE can use when changing numerical features.\n",
    "    Key Points:\n",
    "\n",
    "    The random method is like a quick exploration of \"what if\" scenarios.\n",
    "    DiCE repeats the process of tweaking features and checking predictions many times to find unique and interesting scenarios.\n",
    "    This helps you understand which factors have the biggest impact on your model's predictions.\n",
    "    This understanding can then be used to improve your model or make better decisions based on the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_range(value):\n",
    "    \"\"\"\n",
    "    Generate a range of values between 80% and 100% of the input value.\n",
    "\n",
    "    Parameters:\n",
    "    value (float): The input value.\n",
    "\n",
    "    Returns:\n",
    "    list: A list containing the lower and upper bounds of the range.\n",
    "    \"\"\"\n",
    "    lower_bound = value * 0.8\n",
    "    upper_bound = value * 1\n",
    "    return [lower_bound, upper_bound]\n",
    "\n",
    "\n",
    "def generate_dice_explanation(test_data, features_to_vary, xgb_model,explainer,total_CFs=3,desired_class=0, top_N=3, diversity_weight=1):\n",
    "    \"\"\"\n",
    "    Generate DiCE explanations for a given test instance.\n",
    "\n",
    "    Parameters:\n",
    "    test_data (DataFrame): The test data.\n",
    "    features_to_vary (list): The features to vary in the counterfactuals.\n",
    "    xgb_model (XGBClassifier): The trained XGBoost model.\n",
    "    explainer (DiCE): The DiCE explainer.\n",
    "    total_CFs (int, optional): The total number of counterfactuals to generate. Defaults to 3.\n",
    "    desired_class (int, optional): The desired class for the counterfactuals. Defaults to 0.\n",
    "    top_N (int, optional): The top N counterfactuals to return. Defaults to 3.\n",
    "    diversity_weight (float, optional): The weight for diversity in the counterfactuals. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the actual instance, all counterfactuals, and the top N counterfactuals.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "\n",
    "        query_instance=test_data[xgb_model.feature_names]\n",
    "        \n",
    "        monthly_charge_range = generate_range(query_instance['monthlycharges'])        \n",
    "        dice_exp = explainer.generate_counterfactuals(query_instance, total_CFs=total_CFs, desired_class=desired_class, features_to_vary=features_to_vary,\n",
    "            permitted_range={'contract': ['One year', 'Two year'],\n",
    "                             'monthlycharges': generate_range(query_instance['monthlycharges'])},\n",
    "                             diversity_weight=diversity_weight,\n",
    "                             random_seed=42)\n",
    "\n",
    "        x1 = query_instance.copy()\n",
    "        x1=x1[xgb_model.feature_names]\n",
    "        x1['churn_prob'] = xgb_model.predict(xgb.DMatrix(x1, enable_categorical=True))\n",
    "        x1['type'] = 'actual'\n",
    "\n",
    "        x2 = dice_exp.cf_examples_list[0].final_cfs_df\n",
    "        x2=x2[xgb_model.feature_names]\n",
    "        x2['churn_prob'] = xgb_model.predict(xgb.DMatrix(x2, enable_categorical=True))\n",
    "        x2['type'] = 'counterfactual'\n",
    "\n",
    "        x3=x2.sort_values(by='churn_prob',ascending=True).head(top_N)\n",
    "        x3=x3[x3['churn_prob']<x1['churn_prob'].values[0]]\n",
    "\n",
    "        return x1,x2,x3\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate counterfactual for instance {test_data.index[0]}: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def identify_changes_with_impact(actual, counter_factual):\n",
    "    \"\"\"\n",
    "    Identify the changes in the counterfactuals that have an impact on the prediction.\n",
    "\n",
    "    Parameters:\n",
    "    actual (DataFrame): The actual instance.\n",
    "    counter_factual (DataFrame): The counterfactual instances.\n",
    "\n",
    "    Returns:\n",
    "    str: A JSON string representing the changes and their impact.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store the changes\n",
    "    changes = []\n",
    "\n",
    "    # Get the actual instance\n",
    "    actual_instance = actual.iloc[0]\n",
    "\n",
    "    # Iterate over the rows of counter_factual\n",
    "    for i in range(len(counter_factual)):\n",
    "        # Get the counterfactual instance\n",
    "        counterfactual = counter_factual.iloc[i]\n",
    "\n",
    "        # Initialize an empty dictionary to store the changes for this row\n",
    "        row_changes = {\"recommendation_rank\": i + 1}\n",
    "\n",
    "        # Iterate over the features\n",
    "        for feature in actual.columns:\n",
    "            # If the feature value has changed and the feature is not 'type'\n",
    "            if feature!='churn_prob':\n",
    "                if actual_instance[feature] != counterfactual[feature] and feature != 'type':\n",
    "                    # Add the change to the dictionary\n",
    "                    row_changes[feature] = f'{actual_instance[feature]} -> {counterfactual[feature]}'\n",
    "\n",
    "        # Add the impact on churn probability\n",
    "        initial_prob = float(actual_instance['churn_prob'])\n",
    "        new_prob = float(counterfactual['churn_prob'])\n",
    "        reduction = initial_prob - new_prob\n",
    "        row_changes['impact'] = f\"Churn probability reduced by {reduction * 100:.2f}%\"\n",
    "\n",
    "        # Add the changes for this row to the list\n",
    "        changes.append(row_changes)\n",
    "\n",
    "    # Convert the list to a JSON object\n",
    "    changes_json = json.dumps(changes, indent=4)\n",
    "\n",
    "    return changes_json\n",
    "\n",
    "# Visualize the counterfactuals\n",
    "#dice_exp.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create the base model\n",
    "hist_model = train_hist_model(X_train, dtrain.get_label(), cat_cols)\n",
    "##Create the DICE explainer\n",
    "_,_,exp = create_dice_model(X_train, dtrain.get_label(), num_cols, cat_cols, hist_model)\n",
    "\n",
    "##Get the test data ready for counterfactual analysis\n",
    "test_data=X_test.copy()\n",
    "test_data['customerid']=test_data.index\n",
    "test_data['predicted_churn_probability'] = model.predict(xgb.DMatrix(test_data[model.feature_names], enable_categorical=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[\\n'\n",
      " '    {\\n'\n",
      " '        \"recommendation_rank\": 1,\\n'\n",
      " '        \"contract\": \"Month-to-month -> One year\",\\n'\n",
      " '        \"paymentmethod\": \"Electronic check -> Bank transfer (automatic)\",\\n'\n",
      " '        \"impact\": \"Churn probability reduced by 30.77%\"\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '        \"recommendation_rank\": 2,\\n'\n",
      " '        \"onlinesecurity\": \"Yes -> No\",\\n'\n",
      " '        \"contract\": \"Month-to-month -> One year\",\\n'\n",
      " '        \"impact\": \"Churn probability reduced by 17.26%\"\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '        \"recommendation_rank\": 3,\\n'\n",
      " '        \"multiplelines\": \"Yes -> No\",\\n'\n",
      " '        \"monthlycharges\": \"79.05 -> 64.42\",\\n'\n",
      " '        \"impact\": \"Churn probability reduced by 15.82%\"\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '        \"recommendation_rank\": 4,\\n'\n",
      " '        \"monthlycharges\": \"79.05 -> 67.03\",\\n'\n",
      " '        \"impact\": \"Churn probability reduced by 12.96%\"\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '        \"recommendation_rank\": 5,\\n'\n",
      " '        \"monthlycharges\": \"79.05 -> 68.17\",\\n'\n",
      " '        \"impact\": \"Churn probability reduced by 12.96%\"\\n'\n",
      " '    }\\n'\n",
      " ']')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##Let's test the DICE explanation for a sample query\n",
    "x1,x2,x3=generate_dice_explanation(test_data=test_data.sample(1),\n",
    "                          features_to_vary=['phoneservice',\n",
    "       'multiplelines', 'internetservice', 'onlinesecurity', 'onlinebackup',\n",
    "       'deviceprotection', 'techsupport', 'streamingtv', 'streamingmovies',\n",
    "       'contract', 'paperlessbilling', 'paymentmethod','monthlycharges']\n",
    "       ,xgb_model=model,\n",
    "       explainer=exp,\n",
    "       total_CFs=20,desired_class=0,top_N=5)\n",
    "\n",
    "pprint(identify_changes_with_impact(x1,x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 0:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 1:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 2:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 3:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 4:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 5:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 6:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 7:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 8:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 9:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 10:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 11:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 12:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 13:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 14:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 15:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 16:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 17:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 18:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 19:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 20:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 21:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 22:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 23:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 24:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 25:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 26:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 27:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 28:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 29:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 30:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 31:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 32:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 33:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 34:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 35:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 36:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 37:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 38:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 39:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 40:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 41:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 42:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 43:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 44:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 45:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for instance 46:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##Identify the high propensity churners\n",
    "\n",
    "\n",
    "pred_test=test_data.copy()\n",
    "pred_test['pred']=model.predict(xgb.DMatrix(pred_test[model.feature_names], enable_categorical=True))\n",
    "pred_test=pred_test[pred_test['pred']>0.9]\n",
    "print(pred_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Create an empty DataFrame\n",
    "results = pd.DataFrame(columns=['customer_id', 'changes'])\n",
    "\n",
    "for i in range(len(pred_test)):\n",
    "\n",
    "    test_data_instance = pred_test.iloc[[i]]\n",
    "    features_to_vary = ['phoneservice',\n",
    "       'multiplelines', 'internetservice', 'onlinesecurity', 'onlinebackup',\n",
    "       'deviceprotection', 'techsupport', 'streamingtv', 'streamingmovies',\n",
    "       'contract', 'paperlessbilling', 'paymentmethod','monthlycharges']\n",
    "    \n",
    "   #  shap_df=shap_values[shap_values['customerid']==test_data_instance['customerid'].values[0]]\n",
    "   #  print(shap_df.shape)\n",
    "   #  feature_weights=get_feature_weights_from_df(shap_df=shap_df,row_index=0, selected_features=features_to_vary)\n",
    "   #  print(feature_weights)\n",
    "    \n",
    "    actual, counterfactual, top_counterfactuals = generate_dice_explanation(test_data=test_data_instance, \n",
    "                                                                            features_to_vary=features_to_vary, \n",
    "                                                                            xgb_model=model,\n",
    "                                                                            explainer=exp, \n",
    "                                                                            total_CFs=20, \n",
    "                                                                            desired_class=0,\n",
    "                                                                            top_N=5, \n",
    "                                                                            diversity_weight=1)\n",
    "    changes = identify_changes_with_impact(actual, top_counterfactuals)\n",
    "    print(f\"Changes for instance {i}:\\n\")\n",
    "    # Create a DataFrame for the results and concatenate it with results\n",
    "    results = pd.concat([results, pd.DataFrame({'customer_id': [test_data_instance['customerid'].values[0]], 'changes': [changes]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM to explain the Recommendation\n",
    "\n",
    "Dice Explanation is working great. We have the top 5 best actions to be made to minimize churn by x% as detailed by our xgboost model. \n",
    "Now, we can explain why the churn happens from SHAP and what to do to prevent churn from DICE. Let's pass this info to the LLM agent and use it to create Notes for Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Let's prepare the data, SHAP data and Dice Data to use with GPT Model\n",
    "data=pred_test.copy()\n",
    "data=data.rename(columns={'pred':'predicted_churn'})\n",
    "dice_data=results.copy()\n",
    "\n",
    "\n",
    "test_analyzer=shap_summary.ShapAnalyzer(model=model,\n",
    "                                X_train=data[model.feature_names],\n",
    "                                dtrain=xgb.DMatrix(data[model.feature_names], enable_categorical=True),\n",
    "                                cat_features=cat_cols,\n",
    "                                num_features=num_cols)\n",
    "\n",
    "shap_data=pd.DataFrame(test_analyzer.get_shap_value(),columns=model.feature_names)\n",
    "\n",
    "\n",
    "shap_data['customerid']=data['customerid'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[\\n'\n",
      " '    {\\n'\n",
      " '        \"recommendation_rank\": 1,\\n'\n",
      " '        \"contract\": \"Month-to-month -> Two year\",\\n'\n",
      " '        \"monthlycharges\": \"85.55 -> 72.65\",\\n'\n",
      " '        \"impact\": \"Churn probability reduced by 92.93%\"\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '        \"recommendation_rank\": 2,\\n'\n",
      " '        \"contract\": \"Month-to-month -> Two year\",\\n'\n",
      " '        \"paymentmethod\": \"Electronic check -> Credit card (automatic)\",\\n'\n",
      " '        \"impact\": \"Churn probability reduced by 90.72%\"\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '        \"recommendation_rank\": 3,\\n'\n",
      " '        \"onlinesecurity\": \"No -> No internet service\",\\n'\n",
      " '        \"contract\": \"Month-to-month -> Two year\",\\n'\n",
      " '        \"impact\": \"Churn probability reduced by 89.70%\"\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '        \"recommendation_rank\": 4,\\n'\n",
      " '        \"contract\": \"Month-to-month -> Two year\",\\n'\n",
      " '        \"monthlycharges\": \"85.55 -> 74.1\",\\n'\n",
      " '        \"impact\": \"Churn probability reduced by 88.85%\"\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '        \"recommendation_rank\": 5,\\n'\n",
      " '        \"internetservice\": \"Fiber optic -> No\",\\n'\n",
      " '        \"contract\": \"Month-to-month -> Two year\",\\n'\n",
      " '        \"impact\": \"Churn probability reduced by 88.83%\"\\n'\n",
      " '    }\\n'\n",
      " ']')\n"
     ]
    }
   ],
   "source": [
    "##Let's look at DICE reccomendation for one of the customers\n",
    "pprint(dice_data['changes'].values[1])\n",
    "#Looks great. It correctly  reccomends best action is to Move Contract from Month-To_Mont to Two Years and monthly charges from 85 to 72, which will reduce the churn probability by 90.72%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Let's design the prompt and GPT model chain\n",
    "def create_explanation_prompt(data,shap_data,dice_data,n=None):\n",
    "    \"\"\"\n",
    "    Create a prompt for the GPT model to generate an explanation.\n",
    "\n",
    "    Parameters:\n",
    "    data (DataFrame): The customer data.\n",
    "    shap_data (DataFrame): The SHAP values for each feature.\n",
    "    dice_data (DataFrame): The counterfactuals generated by DiCE.\n",
    "    n (int, optional): The index of the customer to generate an explanation for. If not provided, a random index is chosen.\n",
    "\n",
    "    Returns:\n",
    "    str: The generated prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    if n==None:\n",
    "        n = random.randint(0, dice_data.shape[0] - 1)\n",
    "\n",
    "    predicted_churn=data['predicted_churn'].values[n]\n",
    "    customer = data.drop(columns={'predicted_churn'},axis=0).iloc[n]\n",
    "    shap = shap_data.iloc[n]\n",
    "    dice = dice_data.iloc[n]\n",
    "\n",
    "    # Create a formatted string where each column name is followed by its value\n",
    "    customer_string = ', '.join([f\"{col}={value}\" for col, value in customer.items()])\n",
    "    shap_string = ', '.join([f\"{col}={value}\" for col, value in shap.items()])\n",
    "    dicestring = dice_data['changes'].values[n]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "            YOU ARE AN ASSISTANT TO A CUSTOMER SERVICE AGENT.\n",
    "\n",
    "            Here are the details for a customer the agent is assisting:\n",
    "            - Customer Features: {customer_string}\n",
    "            - Model's Predicted Churn Probability: {predicted_churn}\n",
    "            - Individual SHAP Contributions for Each Feature: {shap_string}\n",
    "            - Top Reccomended actions to Reduce Churn from CounterFactual Analysis: {dicestring}\n",
    "\n",
    "\n",
    "            \n",
    "            Here is the data dicntionary for the dataset:\n",
    "            Customer ID: Unique customer identifier\n",
    "            gender: Whether the customer is a male or a female\n",
    "            SeniorCitizen: Whether the customer is a senior citizen or not (1, 0)\n",
    "            Partner: Whether the customer has a partner or not (Yes, No)\n",
    "            Dependents: Whether the customer has dependents or not (Yes, No)\n",
    "            tenure: Number of months the customer has stayed with the company\n",
    "            PhoneService: Whether the customer has a phone service or not (Yes, No)\n",
    "            MultipleLines: Whether the customer has multiple lines or not (Yes, No, No phone service)\n",
    "            InternetService: Customerâ€™s internet service provider (DSL, Fiber optic, No)\n",
    "            OnlineSecurity: Whether the customer has online security or not (Yes, No, No internet service)\n",
    "            OnlineBackup: Whether the customer has online backup or not (Yes, No, No internet service)\n",
    "            DeviceProtection: Whether the customer has device protection or not (Yes, No, No internet service)\n",
    "            TechSupport: Whether the customer has tech support or not (Yes, No, No internet service)\n",
    "            StreamingTV: Whether the customer has streaming TV or not (Yes, No, No internet service)\n",
    "            StreamingMovies: Whether the customer has streaming movies or not (Yes, No, No internet service)\n",
    "            Contract: The contract term of the customer (Month-to-month, One year, Two year)\n",
    "            PaperlessBilling: Whether the customer has paperless billing or not (Yes, No)\n",
    "            PaymentMethod: The customerâ€™s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n",
    "            MonthlyCharges: The amount charged to the customer monthly\n",
    "            TotalCharges: The total amount charged to the customer\n",
    "            Churn: Whether the customer churned or not (Yes or No)\n",
    "            predicted_churn: the predicted churn probability for the customer by the model\n",
    "\n",
    "\n",
    "            Based on this information, explain to the agent in non-technical terms:\n",
    "            1. Provide summary of who the customer is.\n",
    "                - A short concise summary in under 50 words.\n",
    "            2. What is the customer's predicted churn probability?\n",
    "            Answer in 10 words.\n",
    "            3. Identify the top 3 reasons for the customer's potential churn from the individual shap contribution. Provide a brief explanation (within 50 words for each) of why these \n",
    "                features significantly influence the churn prediction.\n",
    "\n",
    "            4. Suggest the top 5 actions the agent can take to reduce the likelihood of churn, based on the counterfactual analysis. Each suggestion should include:\n",
    "            - Provide the whole counterfactual recommendation for each action.\n",
    "            - If recommendation is to change contraact to two year and Change device protection to \"No internet service\" mention both of them\n",
    "            - DONOT omit information from the counterfactuals\n",
    "            - A concise recommendation (50 words)\n",
    "            - Provide an estimated churn reduction made by this action. Make this estimate from the shap value for each feature.\n",
    "            - Justify why and how this action helps reduce churn by the % you have mentioned, based solely on the data provided and stats.\n",
    "            - Explain this in simple words for agent to understand with a justification of the churn reduction.\n",
    "\n",
    "\n",
    "            Remember:\n",
    "            - The magnitude of a SHAP value indicates the strength of a feature's influence on the prediction.\n",
    "            - **Positive SHAP values increase the likelihood of churn; negative values decrease it.**\n",
    "            - **Positive SHAP values increase the likelihood of churn; negative values decrease it.**\n",
    "            - Recommendations should be strictly based on the information provided in the SHAP contributions , customer features and patterns from decision tree stats.\n",
    "            \"\"\"\n",
    "\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n",
    "chain = (\n",
    "    chat_model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def agent_response(N=49):\n",
    "\n",
    "    \"\"\"\n",
    "    Generate an agent response using the GPT model.\n",
    "\n",
    "    Parameters:\n",
    "    N (int, optional): The index of the customer to generate a response for. Defaults to 49.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    response=chain.invoke(create_explanation_prompt(data=data,shap_data=shap_data,dice_data=dice_data,n=N))\n",
    "    parts = response.split('\\n\\n')\n",
    "\n",
    "    # Extract each part\n",
    "    who_is_customer = parts[0].strip()\n",
    "    churn_probability_explanation = parts[1].strip()\n",
    "    reasons_for_churn = ' '.join(parts[2:3]).strip()\n",
    "    action_recommendations = ' '.join(parts[3:4]).strip()\n",
    "\n",
    "    print(f\"\"\"Who is the customer?\\n{who_is_customer}\\n\\n\"\"\")\n",
    "    print(f\"\"\"Likelihood for Churn\\n{churn_probability_explanation}\\n\\n\"\"\")\n",
    "    print(f\"\"\"Probable Reasons for Churn\\n{reasons_for_churn}\\n\\n\"\"\")\n",
    "    print(f\"\"\"Recommended Actions to Prevent Churn\\n{action_recommendations}\\n\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Run the Chain and get the results for a couple of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the customer?\n",
      "1. Summary of the customer: This male customer is a new subscriber with fiber optic internet, streaming TV, high monthly charges, and a high predicted churn probability.\n",
      "\n",
      "\n",
      "Likelihood for Churn\n",
      "2. Predicted churn probability: High at 91.97%.\n",
      "\n",
      "\n",
      "Probable Reasons for Churn\n",
      "3. Top 3 reasons for potential churn:\n",
      "   - Month-to-month contract: Customers on short contracts are more likely to churn due to the lack of commitment.\n",
      "   - No online security: Lack of online security can lead to dissatisfaction and potential security issues.\n",
      "   - No internet service for streaming movies: Missing out on a popular service may lead to dissatisfaction and churn.\n",
      "\n",
      "\n",
      "Recommended Actions to Prevent Churn\n",
      "4. Top 5 actions to reduce churn:\n",
      "   1. Change online backup to \"No internet service\" and contract to \"Two year.\"\n",
      "      - Churn reduction by 90.23%.\n",
      "      - By offering a long-term contract and removing unnecessary services, the customer is more likely to stay committed.\n",
      "   2. Change tech support to \"No internet service\" and contract to \"Two year.\"\n",
      "      - Churn reduction by 90.22%.\n",
      "      - Providing a stable and long-term service plan can increase customer loyalty and satisfaction.\n",
      "   3. Change online security to \"No internet service\" and contract to \"Two year.\"\n",
      "      - Churn reduction by 90.00%.\n",
      "      - Offering a secure and long-term contract can reassure the customer and reduce the likelihood of churn.\n",
      "   4. Change streaming TV to \"No internet service\" and contract to \"Two year.\"\n",
      "      - Churn reduction by 89.61%.\n",
      "      - While offering popular services is important, ensuring a stable and long-term commitment is crucial for customer retention.\n",
      "   5. Change device protection to \"No internet service\" and contract to \"Two year.\"\n",
      "      - Churn reduction by 89.55%.\n",
      "      - Focusing on essential services and providing a longer-term commitment can enhance customer satisfaction and reduce churn.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent_response(N=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the customer?\n",
      "1. Summary of the customer:\n",
      "   The customer is a male with no partner or dependents, using DSL internet service. He has no phone service, online security, online backup, tech support, and device protection. He watches streaming movies, has a month-to-month contract, and prefers paperless billing.\n",
      "\n",
      "\n",
      "Likelihood for Churn\n",
      "2. Predicted churn probability:\n",
      "   High churn probability at 96.5%.\n",
      "\n",
      "\n",
      "Probable Reasons for Churn\n",
      "3. Top 3 reasons for potential churn:\n",
      "   - Long contract term (Month-to-month) increases churn as customers may prefer flexibility.\n",
      "   - Lack of tech support impacts churn negatively, as customers value assistance.\n",
      "   - Streaming movies positively affect churn; customers may consider this a valuable service.\n",
      "\n",
      "\n",
      "Recommended Actions to Prevent Churn\n",
      "4. Top 5 actions to reduce churn:\n",
      "   1. Change tech support to \"No internet service\" & contract to \"Two year\".\n",
      "      - Churn reduction by 93.73%.\n",
      "      - By offering a longer contract with no tech support, customer loyalty increases due to commitment and reduced service reliance.\n",
      "   2. Change contract to \"Two year\" & monthly charges to $30.19.\n",
      "      - Churn reduction by 90.87%.\n",
      "      - Lowering monthly charges with a longer contract increases customer commitment and perceived value for money.\n",
      "   3. Change streaming movies to \"No\" & contract to \"Two year\".\n",
      "      - Churn reduction by 90.69%.\n",
      "      - Removing streaming movies with a longer contract reduces entertainment options, potentially decreasing the customer's value perception.\n",
      "   4. Change online backup to \"No internet service\" & contract to \"Two year\".\n",
      "      - Churn reduction by 89.45%.\n",
      "      - Eliminating online backup with a longer contract may signify a trade-off in services, enhancing customer commitment.\n",
      "   5. Change online backup to \"Yes\" & contract to \"Two year\".\n",
      "      - Churn reduction by 89.45%.\n",
      "      - Offering online backup with a longer contract provides additional value, increasing customer satisfaction and retention.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent_response(N=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
